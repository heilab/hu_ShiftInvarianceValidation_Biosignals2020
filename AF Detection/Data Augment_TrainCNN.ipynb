{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"./dataset_RRI_augmented/\"\n",
    "dataset_files = [os.path.join(dataset_root,i) for i in os.listdir(dataset_root) if \"cross\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_MaxBlurPool(blur_size,pool_factor):\n",
    "    assert(pool_factor >= 1)\n",
    "    # Add CNN layers left branch (higher frequencies)\n",
    "    # Parameters from paper\n",
    "    WINDOW_SIZE = segment_len\n",
    "    INPUT_FEAT = 1\n",
    "    OUTPUT_CLASS = 2    # output classes\n",
    "    k = 1    # increment every 4th residual block\n",
    "    p = False # pool toggle every other residual block (end with 2^8)\n",
    "    convfilt = 32\n",
    "    convstr = 1\n",
    "    ksize = 16\n",
    "    poolsize = 2\n",
    "    poolstr  = 2\n",
    "    drop = 0.5\n",
    "    \n",
    "    # Modelling with Functional API\n",
    "    #input1 = Input(shape=(None,1), name='input')\n",
    "    input1 = Input(shape=(WINDOW_SIZE,INPUT_FEAT), name='input')\n",
    "    \n",
    "    ## First convolutional block (conv,BN, relu,pool)\n",
    "    x = Conv1D(filters=convfilt,kernel_size=ksize,padding='same',strides=convstr,kernel_initializer='he_normal')(input1)                \n",
    "    x = BatchNormalization()(x)        \n",
    "    x = Activation('relu')(x)  \n",
    "    x = BlurPooling1D(filt_size=blur_size)(x)\n",
    "\n",
    "    for layer in range(pool_factor-1):\n",
    "        x = Conv1D(filters=convfilt,kernel_size=ksize,padding='same',strides=convstr,kernel_initializer='he_normal')(x)                \n",
    "        x = BatchNormalization()(x)        \n",
    "        x = Activation('relu')(x)  \n",
    "        x = BlurPooling1D(filt_size=blur_size)(x)\n",
    "    \n",
    "    # Final bit    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x) \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000)(x)\n",
    "    out = Dense(OUTPUT_CLASS, activation='softmax')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    #sequential_model_to_ascii_printout(model)\n",
    "    #plot_model(model, to_file='CNN.png')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cross_idx,repeat_idx,blur_size,pool_factor,save_root=\"Result_CNN_aug\"):\n",
    "    if not os.path.exists(save_root):\n",
    "        os.mkdir(save_root)\n",
    "    pool_type = \"maxblur-\"\n",
    "    if blur_size > 0:\n",
    "        pool_type = pool_type + str(blur_size)\n",
    "    elif blur_size == 0:\n",
    "        pool_type = \"max\"\n",
    "    elif blur_size == -1:\n",
    "        pool_tyoe = \"avg\"\n",
    "    \n",
    "    save_dir = os.path.join(save_root,\"results_\" + pool_type)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    X_train,y_train,X_test,y_test = load_dataset(cross_idx,dataset_files)\n",
    "    \n",
    "    model_save_dir = os.path.join(save_dir,\"models\")\n",
    "    fig_save_dir = os.path.join(save_dir,\"figs\")\n",
    "    result_path = os.path.join(save_dir,\"result.csv\")\n",
    "\n",
    "    idx = (cross_idx)*10 + repeat_idx + 1\n",
    "    model = CNN_MaxBlurPool(blur_size,pool_factor)\n",
    "    #return model\n",
    "    history = model.fit(X_train,y_train,epochs=epoches,verbose=1)\n",
    "    prediction = model.predict(X_test)\n",
    "    loss,acc = model.evaluate(X_test,y_test)\n",
    "    meta_data = {\"history\":history.history,\"prediction\":prediction}\n",
    "    \n",
    "    print(\"test acc={} , test loss={}\".format(acc,loss))\n",
    "    \n",
    "    model_path = os.path.join(model_save_dir,str(idx)+\"-model.h5\")\n",
    "    save_model(idx,model,model_save_dir)\n",
    "    del model\n",
    "\n",
    "    #save_model_json(idx,model,model_save_dir)\n",
    "    #validate for saved model\n",
    "    #with CustomObjectScope({'BlurPooling1D': BlurPooling1D}):\n",
    "    #    model_loaded = load_model(model_path)\n",
    "    #    _,loaded_acc = model_loaded.evaluate(X_test,y_test)\n",
    "    #print(\"diff=\",acc-loaded_acc)\n",
    "\n",
    "    columns = [\"idx\",\"pool_factor\",\"pool_type\",\"cross_idx\",\"repeat_idx\",\"loss\",\"accuracy\"]\n",
    "    if idx==1:\n",
    "        write_header(file_path=result_path,header=columns)\n",
    "            \n",
    "    #save_graphs(idx,history,prediction,y_test,fig_save_dir)\n",
    "    values = [idx,pool_factor,pool_type,cross_idx,repeat_idx,loss,acc]\n",
    "    df = pd.DataFrame([values],columns=columns)\n",
    "    with open(result_path,\"a\") as f:\n",
    "        df.to_csv(f, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9cd1d27dc250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcross_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrepeat_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mblur_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cross_idx = int(sys.argv[1])\n",
    "    repeat_idx = int(sys.argv[2])\n",
    "    blur_size = int(sys.argv[3])\n",
    "    pool_factor= int(sys.argv[4])\n",
    "    save_root = \"Result_CNN_aug_pool\"+str(pool_factor)\n",
    "    model = main(cross_idx,repeat_idx,blur_size,pool_factor,save_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test keys: ['07162', '04043', '08405']\n",
      "(3408, 100, 1)\n",
      "(3408, 2)\n",
      "(150, 100, 1)\n",
      "(150, 2)\n",
      "Epoch 1/5\n",
      "3408/3408 [==============================] - 3s 958us/step - loss: 0.7399 - accuracy: 0.9061\n",
      "Epoch 2/5\n",
      "3408/3408 [==============================] - 3s 834us/step - loss: 0.2299 - accuracy: 0.9478\n",
      "Epoch 3/5\n",
      "3408/3408 [==============================] - 3s 827us/step - loss: 0.0727 - accuracy: 0.9739\n",
      "Epoch 4/5\n",
      "3408/3408 [==============================] - 3s 857us/step - loss: 0.0527 - accuracy: 0.9824\n",
      "Epoch 5/5\n",
      "3408/3408 [==============================] - 3s 858us/step - loss: 0.0305 - accuracy: 0.9880\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "test acc=0.8199999928474426 , test loss=1.316283339659373\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool_factor = 1\n",
    "    cross_idx = 2\n",
    "    repeat_idx = 1\n",
    "    blur_size = -1\n",
    "    save_root = \"Result_CNN_aug_pool\"+str(pool_factor)\n",
    "    model = main(cross_idx,repeat_idx,blur_size,pool_factor,save_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
