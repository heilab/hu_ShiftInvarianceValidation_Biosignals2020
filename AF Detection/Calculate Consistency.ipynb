{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import matplotlib.animation as animation\n",
    "np.set_printoptions(suppress=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 100\n",
    "dataset_root = \"./dataset_RRI/\"\n",
    "result_root = \"./results_max/\"\n",
    "model_root = os.path.join(result_root,\"models\")\n",
    "keys = [i.split(\".\")[0] for i in os.listdir(dataset_root) if \"pickle\" in i and \"cross\" not in i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2label(label):\n",
    "    if label==0:\n",
    "        return \"Normal\"\n",
    "    elif label==1:\n",
    "        return \"AF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_param(test_keys):\n",
    "    max_norm = 0\n",
    "    min_norm = 10000\n",
    "    for key in keys:\n",
    "        if key in test_keys:continue\n",
    "        with open(os.path.join(dataset_root,key+\".pickle\"),\"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "        X = dataset[\"X\"]\n",
    "        if np.max(X) > max_norm:\n",
    "            max_norm = np.max(X)\n",
    "        if np.min(X) < min_norm:\n",
    "            min_norm = np.min(X)\n",
    "    return min_norm,max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_consistency_once(X,label,seg_idx,model):\n",
    "    continue_seg = np.concatenate( [X[seg_idx],X[seg_idx+1]],axis=0)\n",
    "    sliding_win_start = 1\n",
    "    sliding_win_end = sliding_win_start+win_len\n",
    "    step = 1\n",
    "\n",
    "    consistency_list = [] \n",
    "    slided_data = []\n",
    "    while(sliding_win_end<len(continue_seg)):\n",
    "        data = continue_seg[sliding_win_start:sliding_win_end,:]\n",
    "        slided_data.append(data)\n",
    "        sliding_win_start += step\n",
    "        sliding_win_end += step\n",
    "        \n",
    "    slided_data = np.array(slided_data)\n",
    "    logits = np.argmax(model.predict(slided_data),axis=1)\n",
    "    labels = [label for i in range(len(logits))]\n",
    "    consistency_list = np.array(logits==label,dtype=np.float32)\n",
    "    return consistency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_consistency(X,y,start,end,model):\n",
    "    consistency = []\n",
    "    consistency_normal = []\n",
    "    consistency_af = []\n",
    "    if len(X)==1:\n",
    "        print(\"cosistency of can not calculate cosistency\")\n",
    "        return [],[],[]\n",
    "        \n",
    "    for seg_idx in tqdm_notebook(range(len(X)-1)):\n",
    "        seg = X[seg_idx]\n",
    "        next_seg = X[seg_idx+1]\n",
    "        seg_end = end[seg_idx]\n",
    "        next_seg_start = start[seg_idx+1]\n",
    "        label = np.argmax(y[seg_idx])\n",
    "        next_label = np.argmax(y[seg_idx+1])\n",
    "        if not (seg_end == next_seg_start and label==next_label):continue\n",
    "        consistency_list =  calc_consistency_once(X,label,seg_idx,model)\n",
    "        consistency.append(consistency_list)\n",
    "        \n",
    "        if label == 0:\n",
    "            consistency_normal.append(consistency_list)\n",
    "        else:\n",
    "            consistency_af.append(consistency_list)\n",
    "        \n",
    "    assert(len(consistency_normal)+len(consistency_af) == len(consistency))\n",
    "    #print(\"cosistency of \",test_key,\"=\",np.mean(consistency))\n",
    "    return consistency,consistency_normal,consistency_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_consistency_for_cross(idx,cross_idx):\n",
    "    with open(os.path.join(dataset_root,\"dataset-cross\"+str(cross_idx)+\".pickle\"),\"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "    test_keys = dataset[\"test_key\"]\n",
    "    X_test = dataset[\"X_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "    model = load_model(os.path.join(model_root,str(idx)+\"-model.h5\"))\n",
    "    min_norm,max_norm = get_normalization_param(test_keys)\n",
    "\n",
    "    consistencys = []\n",
    "    consistencys_a = []\n",
    "    consistencys_n = []\n",
    "    for test_key in test_keys:\n",
    "        with open(os.path.join(dataset_root,test_key+\".pickle\"),\"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "        X = np.expand_dims( (dataset[\"X\"] - min_norm) / (max_norm - min_norm) ,axis=2)\n",
    "        y = to_categorical (dataset[\"y\"],num_classes=2)\n",
    "        start = dataset[\"start\"]\n",
    "        end = dataset[\"end\"]\n",
    "        consistency,consistency_normal,consistency_af = calc_consistency(X,y,start,end,model)\n",
    "        consistencys += (consistency)\n",
    "        consistencys_a += consistency_af\n",
    "        consistencys_n += consistency_normal\n",
    "\n",
    "    consistencys = np.concatenate(consistencys,axis=0)\n",
    "    consistencys_a = np.concatenate(consistencys_a,axis=0)\n",
    "    consistencys_n = np.concatenate(consistencys_n,axis=0)\n",
    "    consis = np.mean(consistencys)\n",
    "    consis_a = np.mean(consistencys_a)\n",
    "    consis_n = np.mean(consistencys_n)\n",
    "    return consis,consis_a,consis_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main for Max_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(result_root,\"result.csv\")\n",
    "result_df = pd.read_csv(result_path)\n",
    "result_df = result_df[[\"idx\",\"cross_idx\",\"repeat_idx\",\"loss\",\"accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256630664b3444b487ff4f35d9e14d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hu/.pyenv/versions/3.6.6/envs/Biosignals/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/hu/.pyenv/versions/3.6.6/envs/Biosignals/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consistency = []\n",
    "consistency_a = []\n",
    "consistency_n = []\n",
    "for i in tqdm_notebook(range(len(result_df))):\n",
    "    row = result_df.iloc[i]\n",
    "    cross_idx = int(row[\"cross_idx\"])\n",
    "    idx = int(row[\"idx\"])\n",
    "    consis,consis_a,consis_n = calc_consistency_for_cross(idx,cross_idx)\n",
    "    consistency.append(consis)\n",
    "    consistency_a.append(consis_a)\n",
    "    consistency_n.append(consis_n)\n",
    "result_df[\"consistency\"] = consistency\n",
    "result_df[\"consistency_af\"] = consistency_a\n",
    "result_df[\"consistency_normal\"] = consistency_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"pooling_type\"] = [\"MaxPooling\" for i in range(len(result_df))]\n",
    "result_df.to_csv(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main for Average_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_root = \"./results_avg/\"\n",
    "model_root = os.path.join(result_root,\"models\")\n",
    "result_path = os.path.join(result_root,\"result.csv\")\n",
    "result_df = pd.read_csv(result_path)\n",
    "result_df = result_df[[\"idx\",\"cross_idx\",\"repeat_idx\",\"loss\",\"accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96edabc981104e30afa95210db68b314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hu/.pyenv/versions/3.6.6/envs/Biosignals/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "cosistency of can not calculate cosistency\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consistency = []\n",
    "consistency_a = []\n",
    "consistency_n = []\n",
    "for i in tqdm_notebook(range(len(result_df))):\n",
    "    row = result_df.iloc[i]\n",
    "    cross_idx = int(row[\"cross_idx\"])\n",
    "    idx = int(row[\"idx\"])\n",
    "    consis,consis_a,consis_n = calc_consistency_for_cross(idx,cross_idx)\n",
    "    consistency.append(consis)\n",
    "    consistency_a.append(consis_a)\n",
    "    consistency_n.append(consis_n)\n",
    "result_df[\"consistency\"] = consistency\n",
    "result_df[\"consistency_af\"] = consistency_a\n",
    "result_df[\"consistency_normal\"] = consistency_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"pooling_type\"] = [\"AveragePooling\" for i in range(len(result_df))]\n",
    "result_df.to_csv(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main for BlurMaxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurPooling1D(Layer):\n",
    "    def __init__(self, filt_size=5, stride=2,**kwargs):\n",
    "        self.stride = stride\n",
    "        self.filt_size = filt_size\n",
    "        self.padding = (int(1.*(filt_size-1)/2), int(np.ceil(1.*(filt_size-1)/2)))\n",
    "        if(self.filt_size==1):\n",
    "            self.a = np.array([1.,])\n",
    "        elif(self.filt_size==2):\n",
    "            self.a = np.array([1., 1.])\n",
    "        elif(self.filt_size==3):\n",
    "            self.a = np.array([1., 2., 1.])\n",
    "        elif(self.filt_size==4):    \n",
    "            self.a = np.array([1., 3., 3., 1.])\n",
    "        elif(self.filt_size==5):    \n",
    "            self.a = np.array([1., 4., 6., 4., 1.])\n",
    "        elif(self.filt_size==6):    \n",
    "            self.a = np.array([1., 5., 10., 10., 5., 1.])\n",
    "        elif(self.filt_size==7):    \n",
    "            self.a = np.a\n",
    "            rray([1., 6., 15., 20., 15., 6., 1.])\n",
    "        super(BlurPooling1D, self).__init__(**kwargs)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        win_len = input_shape[1] // self.stride\n",
    "        channels = input_shape[2]\n",
    "        return (input_shape[0], win_len, channels)\n",
    "        \n",
    "    def call(self, x):\n",
    "        k = self.a\n",
    "        k = k / np.sum(k)\n",
    "        k = np.tile(k[:,None,None], (1,x.shape[-1],1) )                \n",
    "        k = K.constant (k, dtype=K.floatx() )\n",
    "\n",
    "        x = K.temporal_padding(x, padding=self.padding)\n",
    "        x = K.conv1d(x,k,strides=self.stride,padding='valid')\n",
    "        \n",
    "        #x = MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_root = \"./results_maxblur-1/\"\n",
    "model_root = os.path.join(result_root,\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
