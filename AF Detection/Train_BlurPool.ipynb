{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hu/.pyenv/versions/3.6.6/envs/Biosignals/lib/python3.6/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/Users/hu/.pyenv/versions/3.6.6/envs/Biosignals/lib/python3.6/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Flatten, Dropout,MaxPooling1D, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurPooling1D(Layer):\n",
    "    def __init__(self, filt_size=5, stride=2,**kwargs):\n",
    "        self.stride = stride\n",
    "        self.filt_size = filt_size\n",
    "        self.padding = (int(1.*(filt_size-1)/2), int(np.ceil(1.*(filt_size-1)/2)))\n",
    "        if(self.filt_size==1):\n",
    "            self.a = np.array([1.,])\n",
    "        elif(self.filt_size==2):\n",
    "            self.a = np.array([1., 1.])\n",
    "        elif(self.filt_size==3):\n",
    "            self.a = np.array([1., 2., 1.])\n",
    "        elif(self.filt_size==4):    \n",
    "            self.a = np.array([1., 3., 3., 1.])\n",
    "        elif(self.filt_size==5):    \n",
    "            self.a = np.array([1., 4., 6., 4., 1.])\n",
    "        elif(self.filt_size==6):    \n",
    "            self.a = np.array([1., 5., 10., 10., 5., 1.])\n",
    "        elif(self.filt_size==7):    \n",
    "            self.a = np.a\n",
    "            rray([1., 6., 15., 20., 15., 6., 1.])\n",
    "        super(BlurPooling1D, self).__init__(**kwargs)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        win_len = input_shape[1] // self.stride\n",
    "        channels = input_shape[2]\n",
    "        return (input_shape[0], win_len, channels)\n",
    "        \n",
    "    def call(self, x):\n",
    "        k = self.a\n",
    "        k = k / np.sum(k)\n",
    "        k = np.tile(k[:,None,None], (1,x.shape[-1],1) )                \n",
    "        k = K.constant (k, dtype=K.floatx() )\n",
    "\n",
    "        x = K.temporal_padding(x, padding=self.padding)\n",
    "        x = K.conv1d(x,k,strides=self.stride,padding='valid')\n",
    "        \n",
    "        #x = MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cmx(true,pred):\n",
    "    cm = confusion_matrix(np.argmax(true,axis=1), np.argmax(pred,axis=1))\n",
    "    classes = [\"N\",\"AF\"]\n",
    "    df_cm = pd.DataFrame(cm, index = classes,\n",
    "                  columns = classes)\n",
    "    plt.figure(figsize = (8,6))\n",
    "    sns.set(font_scale=1.4)#for label size\n",
    "    sns.heatmap(df_cm, annot=True,cmap=\"Blues\",fmt=\"d\",annot_kws={\"size\": 16})# font size\n",
    "    plt.xlabel(\"Predict Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.ylim(len(cm),0)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(cross_idx):\n",
    "    file = dataset_files[cross_idx]\n",
    "    with open(file,\"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "    test_keys = dataset[\"test_key\"]\n",
    "    X_train = dataset[\"X_train\"]\n",
    "    y_train = dataset[\"y_trian\"]\n",
    "    X_test = dataset[\"X_test\"]\n",
    "    y_test = dataset[\"y_test\"]\n",
    "    print(\"test keys:\",test_keys)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_model_MaxBlurPool(blur_size):\n",
    "    # Add CNN layers left branch (higher frequencies)\n",
    "    # Parameters from paper\n",
    "    WINDOW_SIZE = segment_len\n",
    "    INPUT_FEAT = 1\n",
    "    OUTPUT_CLASS = 2    # output classes\n",
    "\n",
    "    k = 1    # increment every 4th residual block\n",
    "    p = False # pool toggle every other residual block (end with 2^8)\n",
    "    convfilt = 32\n",
    "    convstr = 1\n",
    "    ksize = 16\n",
    "    poolsize = 2\n",
    "    poolstr  = 2\n",
    "    drop = 0.5\n",
    "    \n",
    "    # Modelling with Functional API\n",
    "    #input1 = Input(shape=(None,1), name='input')\n",
    "    input1 = Input(shape=(WINDOW_SIZE,INPUT_FEAT), name='input')\n",
    "    \n",
    "    ## First convolutional block (conv,BN, relu)\n",
    "    x = Conv1D(filters=convfilt,\n",
    "               kernel_size=ksize,\n",
    "               padding='same',\n",
    "               strides=convstr,\n",
    "               kernel_initializer='he_normal')(input1)                \n",
    "    x = BatchNormalization()(x)        \n",
    "    x = Activation('relu')(x)  \n",
    "    \n",
    "    ## Second convolutional block (conv, BN, relu, dropout, conv) with residual net\n",
    "    # Left branch (convolutions)\n",
    "    x1 =  Conv1D(filters=convfilt,\n",
    "               kernel_size=ksize,\n",
    "               padding='same',\n",
    "               strides=convstr,\n",
    "               kernel_initializer='he_normal')(x)      \n",
    "    x1 = BatchNormalization()(x1)    \n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(drop)(x1)\n",
    "    x1 =  Conv1D(filters=convfilt,\n",
    "               kernel_size=ksize,\n",
    "               padding='same',\n",
    "               strides=convstr,\n",
    "               kernel_initializer='he_normal')(x1)\n",
    "    #x1 = MaxPooling1D(pool_size=poolsize,strides=poolstr)(x1)\n",
    "    #BlurMaxPooling\n",
    "    x1 = BlurPooling1D(filt_size=blur_size)(x1)\n",
    "    \n",
    "    # Right branch, shortcut branch pooling\n",
    "    #x2 = MaxPooling1D(pool_size=poolsize,strides=poolstr)(x)\n",
    "    x2 = BlurPooling1D(filt_size=blur_size)(x)\n",
    "    \n",
    "    # Merge both branches\n",
    "    x = keras.layers.add([x1, x2])\n",
    "    del x1,x2\n",
    "    \n",
    "    ## Main loop\n",
    "    p = not p \n",
    "    for l in range(2):\n",
    "        if (l%4 == 0) and (l>0): # increment k on every fourth residual block\n",
    "            k += 1\n",
    "             # increase depth by 1x1 Convolution case dimension shall change\n",
    "            xshort = Conv1D(filters=convfilt*k,kernel_size=1)(x)\n",
    "        else:\n",
    "            xshort = x        \n",
    "        # Left branch (convolutions)\n",
    "        # notice the ordering of the operations has changed        \n",
    "        x1 = BatchNormalization()(x)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x1 = Dropout(drop)(x1)\n",
    "        x1 =  Conv1D(filters=convfilt*k,\n",
    "               kernel_size=ksize,\n",
    "               padding='same',\n",
    "               strides=convstr,\n",
    "               kernel_initializer='he_normal')(x1)        \n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x1 = Dropout(drop)(x1)\n",
    "        x1 =  Conv1D(filters=convfilt*k,\n",
    "               kernel_size=ksize,\n",
    "               padding='same',\n",
    "               strides=convstr,\n",
    "               kernel_initializer='he_normal')(x1)        \n",
    "        if p:\n",
    "            #x1 = MaxPooling1D(pool_size=poolsize,strides=poolstr)(x1)  \n",
    "            x1 = BlurPooling1D(filt_size=blur_size)(x1)    \n",
    "        # Right branch: shortcut connection\n",
    "        if p:\n",
    "            #x2 = MaxPooling1D(pool_size=poolsize,strides=poolstr)(xshort)\n",
    "            x2 = BlurPooling1D(filt_size=blur_size)(xshort)\n",
    "        else:\n",
    "            x2 = xshort  # pool or identity            \n",
    "        # Merging branches\n",
    "        x = keras.layers.add([x1, x2])\n",
    "        # change parameters\n",
    "        p = not p # toggle pooling\n",
    "\n",
    "    \n",
    "    # Final bit    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x) \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000)(x)\n",
    "    #x = Dense(1000)(x)\n",
    "    out = Dense(OUTPUT_CLASS, activation='softmax')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    #sequential_model_to_ascii_printout(model)\n",
    "    plot_model(model, to_file='model.png')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graphs(idx,history,prediction,y_test,fig_save_dir=\"./figs\"):\n",
    "    if not os.path.exists(fig_save_dir):\n",
    "        os.mkdir(fig_save_dir)\n",
    "    cmx_save_path = os.path.join(fig_save_dir,\"cmx-\"+str(idx)+\".png\")\n",
    "    acc_save_path = os.path.join(fig_save_dir,\"acc-\"+str(idx)+\".png\")\n",
    "    loss_save_path = os.path.join(fig_save_dir,\"loss-\"+str(idx)+\".png\")\n",
    "    \n",
    "    plot_cmx(pred=prediction,true=y_test)\n",
    "    plt.savefig(cmx_save_path)\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.savefig(loss_save_path)\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.savefig(acc_save_path)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(idx,model,model_save_dir=\"./models\"):\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.mkdir(model_save_dir)\n",
    "    model_save_path = os.path.join(model_save_dir,str(idx)+\"-model.h5\")\n",
    "    model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"./dataset_RRI/\"\n",
    "segment_len = 100\n",
    "fs = 250\n",
    "dataset_files = [os.path.join(dataset_root,i) for i in os.listdir(dataset_root) if \"cross\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 10\n",
    "repeat = 10\n",
    "cross = 5\n",
    "records = []\n",
    "use_blurpool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(blur_size):\n",
    "    save_root = \"./results_maxblur-\" + str(blur_size)\n",
    "    if not os.path.exists(save_root):\n",
    "        os.mkdir(save_root)\n",
    "\n",
    "    model_save_dir = os.path.join(save_root,\"models\")\n",
    "    fig_save_dir = os.path.join(save_root,\"figs\")\n",
    "    result_save_path = os.path.join(save_root,\"result.csv\")\n",
    "\n",
    "\n",
    "    for cross_idx in range(cross):\n",
    "        X_train,y_train,X_test,y_test = load_dataset(cross_idx)\n",
    "        for repeat_idx in range(repeat):\n",
    "            idx = (cross_idx)*10 + repeat_idx + 1\n",
    "            if use_blurpool:\n",
    "                model = ResNet_model_MaxBlurPool(blur_size)\n",
    "            else:\n",
    "                model = ResNet_model()\n",
    "            history = model.fit(X_train,y_train,epochs=epoches,verbose=1)\n",
    "            prediction = model.predict(X_test)\n",
    "            loss,acc = model.evaluate(X_test,y_test)\n",
    "            print(\"test acc={0:.2f} , test loss={1:.2f}\".format(acc,loss))\n",
    "            save_model(idx,model,model_save_dir)\n",
    "            save_graphs(idx,history,prediction,y_test,fig_save_dir)\n",
    "            records.append({\"idx\":idx,\"cross_idx\":cross_idx,\"repeat_idx\":repeat_idx,\"loss\":loss,\"accuracy\":acc})\n",
    "\n",
    "    result_df = pd.DataFrame.from_records(records)\n",
    "    print(\"5-cross-validated accuaracy =\",np.mean(result_df.accuracy))\n",
    "    print(\"5-cross-validated loss =\",np.mean(result_df.loss))\n",
    "    result_df.to_csv(result_save_path,header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test keys: ['05261', '06453', '07162']\n",
      "(1408, 100, 1)\n",
      "(1408, 2)\n",
      "(148, 100, 1)\n",
      "(148, 2)\n",
      "WARNING:tensorflow:From /Users/hu/.pyenv/versions/3.6.6/envs/Biosignals/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1408/1408 [==============================] - 3s 2ms/step - loss: 1.4429 - accuracy: 0.5483\n",
      "Epoch 2/10\n",
      "1408/1408 [==============================] - 1s 939us/step - loss: 0.7954 - accuracy: 0.5575\n",
      "Epoch 3/10\n",
      "1408/1408 [==============================] - 1s 936us/step - loss: 0.8497 - accuracy: 0.5547\n",
      "Epoch 4/10\n",
      "1408/1408 [==============================] - 1s 935us/step - loss: 0.7834 - accuracy: 0.5597\n",
      "Epoch 5/10\n",
      "1408/1408 [==============================] - 1s 940us/step - loss: 0.7347 - accuracy: 0.5476\n",
      "Epoch 6/10\n",
      "1408/1408 [==============================] - 1s 957us/step - loss: 0.7756 - accuracy: 0.5589\n",
      "Epoch 7/10\n",
      "1408/1408 [==============================] - 1s 958us/step - loss: 0.7213 - accuracy: 0.5490\n",
      "Epoch 8/10\n",
      "1408/1408 [==============================] - 1s 971us/step - loss: 0.8330 - accuracy: 0.5440\n",
      "Epoch 9/10\n",
      "1408/1408 [==============================] - 1s 960us/step - loss: 0.7249 - accuracy: 0.5476\n",
      "Epoch 10/10\n",
      "1408/1408 [==============================] - 1s 976us/step - loss: 0.6351 - accuracy: 0.6641\n",
      "148/148 [==============================] - 0s 1ms/step\n",
      "test acc=0.53 , test loss=0.69\n",
      "Epoch 1/10\n",
      "1408/1408 [==============================] - 3s 2ms/step - loss: 1.8063 - accuracy: 0.5618\n",
      "Epoch 2/10\n",
      "1408/1408 [==============================] - 1s 1ms/step - loss: 1.0464 - accuracy: 0.6143\n",
      "Epoch 3/10\n",
      " 480/1408 [=========>....................] - ETA: 0s - loss: 0.8545 - accuracy: 0.6875"
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "#    blur_size = sys.argv[1]\n",
    "#    main(blur_size)\n",
    "    blur_size = 1\n",
    "    main(blur_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
